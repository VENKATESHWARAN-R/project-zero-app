# Project Zero App - Authentication Service

A secure, production-ready JWT-based authentication microservice for the Project Zero App e-commerce platform.

## ðŸŽ¯ Overview

The Authentication Service provides centralized user authentication and authorization for the Project Zero App ecosystem. It implements industry-standard security practices including JWT tokens, bcrypt password hashing, rate limiting, and comprehensive input validation.

### Key Features

- **ðŸ” JWT Authentication**: Access and refresh token pattern with configurable expiration
- **ðŸ›¡ï¸ Security First**: bcrypt password hashing (12 salt rounds), rate limiting, account lockouts
- **ðŸš€ High Performance**: Async FastAPI with SQLAlchemy ORM
- **ðŸ“Š Monitoring**: Health checks, structured logging, comprehensive metrics
- **ðŸ§ª Test Coverage**: 94+ passing tests with TDD methodology
- **ðŸ³ Cloud Ready**: Docker containerized with GCP deployment support
- **ðŸ”„ Microservice Architecture**: Designed for distributed systems and service mesh

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â”€â”€â”€â”€â”‚  Auth Service    â”‚â”€â”€â”€â”€â”‚   Database      â”‚
â”‚  (React/Next)   â”‚    â”‚  (FastAPI)       â”‚    â”‚  (SQLite/PG)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Other Services  â”‚
                       â”‚ (Product, Order) â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

- **Framework**: FastAPI (async Python web framework)
- **Database**: SQLite (development) / PostgreSQL (production)
- **ORM**: SQLAlchemy 2.0 with declarative models
- **Authentication**: JWT tokens with PyJWT
- **Password Security**: bcrypt with configurable rounds
- **Validation**: Pydantic v2 models
- **Testing**: pytest with async support
- **Containerization**: Docker with multi-stage builds

## ðŸš€ Quick Start

### Prerequisites

- Python 3.13+
- uv (Python package manager)
- Docker (optional, for containerization)

### Local Development

1. **Clone and Setup**
   ```bash
   cd services/auth-service
   uv sync
   ```

2. **Environment Configuration**
   ```bash
   # Copy example environment file
   cp .env.example .env

   # Edit configuration as needed
   nano .env
   ```

3. **Run the Service**
   ```bash
   # Development mode with auto-reload
   uv run uvicorn main:app --host 0.0.0.0 --port 8001 --reload

   # Production mode
   uv run uvicorn main:app --host 0.0.0.0 --port 8001
   ```

4. **Access the API**
   - API Documentation: http://localhost:8001/docs
   - Health Check: http://localhost:8001/health
   - Service Info: http://localhost:8001/

### Using Docker

1. **Build the Image**
   ```bash
   docker build -t auth-service .
   ```

2. **Run the Container**
   ```bash
   docker run -p 8001:8001 -e DATABASE_URL="sqlite:///./auth.db" auth-service
   ```

## ðŸ“¡ API Endpoints

### Authentication Endpoints

| Method | Endpoint | Description | Auth Required | Status |
|--------|----------|-------------|---------------|--------|
| POST | `/auth/login` | User login with email/password | No | âœ… Implemented |
| POST | `/auth/logout` | Invalidate refresh token | No | âœ… Implemented |
| POST | `/auth/refresh` | Get new access token | No | âœ… Implemented |
| GET | `/auth/verify` | Verify access token | Yes | âœ… Implemented |
| POST | `/auth/register` | User registration | No | âœ… Implemented |

### System Endpoints

| Method | Endpoint | Description | Auth Required | Status |
|--------|----------|-------------|---------------|--------|
| GET | `/` | Service information | No | âœ… Implemented |
| GET | `/health` | Health check with database status | No | âœ… Implemented |
| GET | `/health/ready` | Readiness check | No | âœ… Implemented |
| GET | `/docs` | Interactive API documentation | No | âœ… Implemented |

### ðŸ§ª Testing with cURL

#### 1. Service Health Check
```bash
# Check if service is running
curl -X GET http://localhost:8001/health

# Expected Response:
# {
#   "status": "healthy",
#   "timestamp": "2025-09-23T10:30:00Z",
#   "database": "connected"
# }
```

#### 2. User Login (Authentication)
```bash
# Login with credentials
curl -X POST http://localhost:8001/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "SecurePass123"
  }'

# Expected Response (Success):
# {
#   "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
#   "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
#   "token_type": "bearer",
#   "expires_in": 900
# }

# Expected Response (Invalid Credentials):
# HTTP 401 - {"detail": "Invalid email or password"}

# Expected Response (Too Many Attempts):
# HTTP 429 - {"detail": "Too many login attempts. Try again after..."}
```

#### 3. User Registration
```bash
# Register a new user
curl -X POST http://localhost:8001/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "newuser@example.com",
    "password": "SecurePass123"
  }'

# Expected Response (Success):
# {
#   "user_id": 123,
#   "email": "newuser@example.com",
#   "message": "User registered successfully"
# }

# Expected Response (User Already Exists):
# HTTP 409 - {"detail": "User already exists"}

# Expected Response (Weak Password):
# HTTP 422 - {"detail": "Password validation failed: ..."}

# Expected Response (Invalid Email):
# HTTP 422 - {"detail": "Invalid email format"}
```

#### 4. Token Verification
```bash
# Verify access token (replace with actual token)
ACCESS_TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

curl -X GET http://localhost:8001/auth/verify \
  -H "Authorization: Bearer $ACCESS_TOKEN"

# Expected Response (Valid Token):
# {
#   "valid": true,
#   "user_id": 123,
#   "email": "test@example.com"
# }

# Expected Response (Invalid/Expired Token):
# HTTP 401 - {"detail": "Invalid or expired token"}
```

#### 5. Token Refresh
```bash
# Refresh access token using refresh token
REFRESH_TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

curl -X POST http://localhost:8001/auth/refresh \
  -H "Content-Type: application/json" \
  -d "{
    \"refresh_token\": \"$REFRESH_TOKEN\"
  }"

# Expected Response:
# {
#   "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
#   "token_type": "bearer",
#   "expires_in": 900
# }
```

#### 6. User Logout
```bash
# Logout (invalidate refresh token)
REFRESH_TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

curl -X POST http://localhost:8001/auth/logout \
  -H "Content-Type: application/json" \
  -d "{
    \"refresh_token\": \"$REFRESH_TOKEN\"
  }"

# Expected Response:
# {
#   "message": "Successfully logged out"
# }
```

#### 7. Complete Login Flow Test
```bash
#!/bin/bash
# Save as test_auth_flow.sh

BASE_URL="http://localhost:8001"

echo "1. Health Check..."
curl -s "$BASE_URL/health" | jq '.'

echo -e "\n2. Register New User..."
curl -s -X POST "$BASE_URL/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "testuser@example.com",
    "password": "SecurePass123"
  }' | jq '.'

echo -e "\n3. Login..."
LOGIN_RESPONSE=$(curl -s -X POST "$BASE_URL/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "testuser@example.com",
    "password": "SecurePass123"
  }')

echo "$LOGIN_RESPONSE" | jq '.'

# Extract tokens
ACCESS_TOKEN=$(echo "$LOGIN_RESPONSE" | jq -r '.access_token')
REFRESH_TOKEN=$(echo "$LOGIN_RESPONSE" | jq -r '.refresh_token')

echo -e "\n4. Verify Token..."
curl -s -X GET "$BASE_URL/auth/verify" \
  -H "Authorization: Bearer $ACCESS_TOKEN" | jq '.'

echo -e "\n5. Refresh Token..."
curl -s -X POST "$BASE_URL/auth/refresh" \
  -H "Content-Type: application/json" \
  -d "{\"refresh_token\": \"$REFRESH_TOKEN\"}" | jq '.'

echo -e "\n6. Logout..."
curl -s -X POST "$BASE_URL/auth/logout" \
  -H "Content-Type: application/json" \
  -d "{\"refresh_token\": \"$REFRESH_TOKEN\"}" | jq '.'
```

### ðŸ”§ Error Responses

#### Common HTTP Status Codes
- **200 OK**: Successful operation (login, logout, refresh, verify)
- **201 Created**: Resource created successfully (registration)
- **401 Unauthorized**: Invalid credentials or token
- **409 Conflict**: Resource already exists (user already registered)
- **422 Unprocessable Entity**: Validation errors (weak password, invalid email)
- **429 Too Many Requests**: Rate limit exceeded
- **500 Internal Server Error**: Server error

#### Error Response Format
```json
{
  "detail": "Error message describing what went wrong",
  "error_code": "MACHINE_READABLE_CODE"
}
```

## ðŸ”§ Configuration

### Environment Variables

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `DATABASE_URL` | Database connection string | `sqlite:///./auth_service.db` | No |
| `JWT_SECRET_KEY` | Secret key for JWT signing | Auto-generated | No |
| `JWT_ALGORITHM` | JWT signing algorithm | `HS256` | No |
| `ACCESS_TOKEN_EXPIRE_MINUTES` | Access token lifetime | `15` | No |
| `REFRESH_TOKEN_EXPIRE_DAYS` | Refresh token lifetime | `30` | No |
| `BCRYPT_ROUNDS` | Password hashing rounds | `12` | No |
| `PORT` | Service port | `8001` | No |
| `HOST` | Service host | `0.0.0.0` | No |

### Database Configuration

#### Development (SQLite) - Current Implementation
```env
DATABASE_URL=sqlite:///./auth_service.db
```

#### Production (PostgreSQL) - Recommended
```env
DATABASE_URL=postgresql://user:password@host:port/database

# Example for local PostgreSQL
DATABASE_URL=postgresql://authuser:securepass@localhost:5432/authdb

# Example for Cloud SQL (GCP)
DATABASE_URL=postgresql://authuser:securepass@/authdb?host=/cloudsql/project:region:instance
```

### Security Settings

- **Password Requirements**: Minimum 8 characters, mixed case, numbers required
- **Rate Limiting**: 5 failed attempts per 15 minutes, 15-minute lockout
- **Token Security**: Access tokens expire in 15 minutes, refresh tokens in 30 days
- **Password Hashing**: bcrypt with 12 salt rounds (2025 standard)

## ðŸ§ª Testing

### Run Tests
```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src --cov-report=html

# Run specific test categories
uv run pytest tests/contract/     # Contract tests
uv run pytest tests/integration/ # Integration tests
```

### Test Categories

- **Contract Tests**: API endpoint behavior and response structure
- **Integration Tests**: End-to-end workflows and security features
- **Unit Tests**: Individual component functionality

## ðŸ³ Docker Deployment

### Dockerfile Features

- **Multi-stage build**: Optimized for production
- **Security**: Non-root user, minimal attack surface
- **Performance**: Compiled dependencies, optimized layers
- **Health checks**: Built-in container health monitoring

### Build Arguments

- `PYTHON_VERSION`: Python version (default: 3.13)
- `PORT`: Service port (default: 8001)

### Docker Compose

```yaml
version: '3.8'
services:
  auth-service:
    build: .
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/auth
      - JWT_SECRET_KEY=your-secret-key
    depends_on:
      - db
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=auth
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

## â˜ï¸ Cloud Deployment (GCP)

### Google Cloud Platform Deployment

#### 1. Cloud Run (Serverless)

```bash
# Build and push to Container Registry
gcloud builds submit --tag gcr.io/PROJECT_ID/auth-service

# Deploy to Cloud Run
gcloud run deploy auth-service \
  --image gcr.io/PROJECT_ID/auth-service \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 8001 \
  --set-env-vars DATABASE_URL="postgresql://..." \
  --set-env-vars JWT_SECRET_KEY="your-secret-key"
```

#### 2. Google Kubernetes Engine (GKE)

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
    spec:
      containers:
      - name: auth-service
        image: gcr.io/PROJECT_ID/auth-service
        ports:
        - containerPort: 8001
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: auth-secrets
              key: database-url
        livenessProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: auth-service
spec:
  selector:
    app: auth-service
  ports:
  - port: 80
    targetPort: 8001
  type: LoadBalancer
```

#### 3. Database Options

**Cloud SQL (PostgreSQL)**
```bash
# Create Cloud SQL instance
gcloud sql instances create auth-db \
  --database-version=POSTGRES_15 \
  --tier=db-f1-micro \
  --region=us-central1

# Create database and user
gcloud sql databases create auth --instance=auth-db
gcloud sql users create authuser --instance=auth-db --password=secure-password
```

**Cloud Spanner (Enterprise)**
```env
DATABASE_URL=spanner://PROJECT_ID/INSTANCE_ID/DATABASE_ID
```

### Service Mesh Integration

#### Istio Service Mesh

```yaml
# virtualservice.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: auth-service
spec:
  hosts:
  - auth-service
  http:
  - match:
    - uri:
        prefix: /auth
    route:
    - destination:
        host: auth-service
        port:
          number: 8001
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
```

### Monitoring and Observability

#### Cloud Monitoring Integration

```python
# Add to main.py for Cloud Monitoring
from google.cloud import monitoring_v3

# Metrics export
def export_metrics():
    client = monitoring_v3.MetricServiceClient()
    # Custom metrics implementation
```

#### Cloud Logging

```python
# Structured logging for Cloud Logging
import structlog
from google.cloud import logging

# Configure structured logging
logging_client = logging.Client()
logging_client.setup_logging()
```

## ðŸ—„ï¸ PostgreSQL Migration Guide

### Why Migrate from SQLite to PostgreSQL?

SQLite is excellent for development and testing, but PostgreSQL offers production-grade features:

- **Concurrent Connections**: Handle multiple simultaneous users
- **ACID Compliance**: Better transaction isolation and consistency
- **Performance**: Optimized for read/write heavy workloads
- **Scalability**: Horizontal scaling with read replicas
- **Advanced Features**: JSON columns, full-text search, extensions
- **Cloud Integration**: Native support in GCP Cloud SQL, AWS RDS, Azure Database

### ðŸ“‹ Migration Steps

#### 1. Install PostgreSQL Dependencies

```bash
# Add PostgreSQL driver to requirements
echo "psycopg2-binary==2.9.9" >> requirements.txt

# Or using uv
uv add psycopg2-binary
```

#### 2. Set Up Local PostgreSQL

##### Option A: Docker PostgreSQL (Recommended for Development)
```bash
# Create docker-compose.yml for PostgreSQL
cat > docker-compose.dev.yml << EOF
version: '3.8'
services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: authdb
      POSTGRES_USER: authuser
      POSTGRES_PASSWORD: securepass123
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U authuser -d authdb"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
EOF

# Start PostgreSQL
docker-compose -f docker-compose.dev.yml up -d postgres

# Verify connection
psql -h localhost -U authuser -d authdb -c "SELECT version();"
```

##### Option B: Native PostgreSQL Installation
```bash
# macOS (using Homebrew)
brew install postgresql@15
brew services start postgresql@15
createdb authdb
createuser authuser

# Ubuntu/Debian
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo -u postgres createdb authdb
sudo -u postgres createuser authuser

# Create user and database
sudo -u postgres psql -c "CREATE USER authuser WITH PASSWORD 'securepass123';"
sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE authdb TO authuser;"
```

#### 3. Create Database Initialization Script

```sql
-- Save as init-db.sql
-- Database initialization for auth service

-- Create database (if using manual setup)
-- CREATE DATABASE authdb;

-- Connect to the database
\c authdb;

-- Create user table (will be created by SQLAlchemy, but useful for reference)
-- This matches the User model in src/models/user.py

/*
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    is_active BOOLEAN DEFAULT true,
    failed_login_attempts INTEGER DEFAULT 0,
    locked_until TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for performance
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_users_active ON users(is_active);
CREATE INDEX IF NOT EXISTS idx_users_locked ON users(locked_until);

-- Create trigger for updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
*/

-- Grant permissions
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO authuser;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO authuser;
GRANT ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA public TO authuser;

-- Enable necessary extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";  -- For UUID generation
CREATE EXTENSION IF NOT EXISTS "pg_trgm";    -- For faster text search

-- Verify setup
SELECT 'PostgreSQL setup complete!' as status;
```

#### 4. Update Environment Configuration

```bash
# Update .env file
cp .env .env.sqlite.backup

cat > .env << EOF
# PostgreSQL Configuration
DATABASE_URL=postgresql://authuser:securepass123@localhost:5432/authdb

# JWT Configuration
JWT_SECRET_KEY=your-super-secret-jwt-key-here-min-256-bits
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=15
REFRESH_TOKEN_EXPIRE_DAYS=30

# Security Configuration
BCRYPT_ROUNDS=12

# Server Configuration
HOST=0.0.0.0
PORT=8001

# Development Settings
DEBUG=true
LOG_LEVEL=INFO
EOF
```

#### 5. Test Database Connection

```bash
# Test connection with the service
cd services/auth-service

# Install dependencies with PostgreSQL support
uv sync

# Test database connection
python -c "
from src.database import engine, get_db
from sqlalchemy import text

try:
    with engine.connect() as conn:
        result = conn.execute(text('SELECT version()'))
        print('âœ… PostgreSQL connection successful!')
        print(f'Version: {result.fetchone()[0]}')
except Exception as e:
    print(f'âŒ Connection failed: {e}')
"
```

#### 6. Initialize Database Schema

```bash
# Start the service to create tables
uv run uvicorn main:app --host 0.0.0.0 --port 8001

# Or manually create tables
python -c "
from src.database import create_tables
create_tables()
print('âœ… Database tables created!')
"
```

#### 7. Data Migration (If Needed)

```bash
# Export data from SQLite (if you have existing data)
python -c "
import sqlite3
import json

# Connect to SQLite
sqlite_conn = sqlite3.connect('auth_service.db')
cursor = sqlite_conn.cursor()

# Export users
cursor.execute('SELECT * FROM users')
users = cursor.fetchall()

# Save to JSON for migration
with open('users_export.json', 'w') as f:
    json.dump(users, f, indent=2)

print(f'Exported {len(users)} users to users_export.json')
sqlite_conn.close()
"

# Import to PostgreSQL
python -c "
import json
from src.database import get_db
from src.models.user import User

# Load exported data
with open('users_export.json', 'r') as f:
    users_data = json.load(f)

# Import to PostgreSQL
db = next(get_db())
for user_data in users_data:
    user = User(
        email=user_data[1],  # Adjust indices based on SQLite schema
        password_hash=user_data[2],
        is_active=user_data[3]
    )
    db.add(user)

db.commit()
print(f'Imported {len(users_data)} users to PostgreSQL')
"
```

### ðŸ§ª Testing PostgreSQL Integration

```bash
# Complete test suite with PostgreSQL
uv run pytest --cov=src --cov-report=html

# Test specific database operations
uv run pytest tests/integration/ -v

# Test with Docker PostgreSQL
DATABASE_URL=postgresql://authuser:securepass123@localhost:5432/authdb \
uv run pytest tests/contract/test_auth_login.py -v
```

### ðŸš€ Production PostgreSQL Setup

#### Google Cloud SQL (Recommended for GCP)

```bash
# Create Cloud SQL instance
gcloud sql instances create auth-postgres \
  --database-version=POSTGRES_15 \
  --tier=db-g1-small \
  --region=us-central1 \
  --storage-type=SSD \
  --storage-size=20GB \
  --backup-start-time=03:00 \
  --maintenance-window-day=SUN \
  --maintenance-window-hour=04 \
  --enable-bin-log

# Create database and user
gcloud sql databases create authdb --instance=auth-postgres
gcloud sql users create authuser --instance=auth-postgres --password=your-secure-password

# Get connection details
gcloud sql instances describe auth-postgres

# Connection string for Cloud SQL
DATABASE_URL=postgresql://authuser:password@/authdb?host=/cloudsql/project:region:instance
```

#### AWS RDS Setup

```bash
# Using AWS CLI
aws rds create-db-instance \
  --db-instance-identifier auth-postgres \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version 15.4 \
  --master-username authuser \
  --master-user-password your-secure-password \
  --allocated-storage 20 \
  --vpc-security-group-ids sg-xxxxxxxxx \
  --backup-retention-period 7 \
  --storage-encrypted

# Connection string
DATABASE_URL=postgresql://authuser:password@auth-postgres.xxxxx.region.rds.amazonaws.com:5432/authdb
```

### ðŸ”§ PostgreSQL Performance Optimization

#### Connection Pooling

```python
# Add to src/database.py for production
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,           # Number of connections to maintain
    max_overflow=30,        # Additional connections when pool is full
    pool_pre_ping=True,     # Validate connections before use
    pool_recycle=3600,      # Recycle connections every hour
    echo=False              # Set to True for SQL debugging
)
```

#### Database Monitoring

```sql
-- Useful PostgreSQL monitoring queries

-- Check connection status
SELECT count(*) as total_connections,
       count(*) FILTER (WHERE state = 'active') as active_connections
FROM pg_stat_activity;

-- Check table sizes
SELECT schemaname, tablename,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public';

-- Check slow queries
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;
```

### ðŸ› ï¸ Troubleshooting

#### Common Issues

```bash
# Connection refused
# Check if PostgreSQL is running
sudo systemctl status postgresql
# or for Docker
docker-compose ps

# Permission denied
# Ensure user has proper permissions
psql -h localhost -U authuser -d authdb -c "\du"

# SSL/TLS issues in production
# Add SSL parameters to connection string
DATABASE_URL=postgresql://user:pass@host:5432/db?sslmode=require&sslcert=client-cert.pem&sslkey=client-key.pem&sslrootcert=ca-cert.pem

# Connection pool exhaustion
# Monitor and adjust pool settings
tail -f logs/auth-service.log | grep "pool"
```

## ðŸ”„ Service Integration

### Inter-Service Communication

#### 1. Service-to-Service Authentication

```python
# Other services verify tokens via this service
async def verify_service_token(token: str) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{AUTH_SERVICE_URL}/auth/verify",
            headers={"Authorization": f"Bearer {token}"}
        )
        return response.json()
```

#### 2. API Gateway Integration

```yaml
# Kong/Ambassador API Gateway
apiVersion: getambassador.io/v2
kind: Mapping
metadata:
  name: auth-service
spec:
  prefix: /auth
  service: auth-service:8001
  timeout_ms: 30000
```

#### 3. Load Balancer Configuration

```nginx
# Nginx upstream for auth service
upstream auth_service {
    server auth-service-1:8001;
    server auth-service-2:8001;
    server auth-service-3:8001;
}

location /auth {
    proxy_pass http://auth_service;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
}
```

### Event-Driven Architecture

#### User Events Publisher

```python
# Publish user events to Pub/Sub
from google.cloud import pubsub_v1

async def publish_user_event(event_type: str, user_id: int, data: dict):
    publisher = pubsub_v1.PublisherClient()
    topic_path = publisher.topic_path(PROJECT_ID, "user-events")

    message = {
        "event_type": event_type,
        "user_id": user_id,
        "timestamp": datetime.utcnow().isoformat(),
        "data": data
    }

    publisher.publish(topic_path, json.dumps(message).encode())
```

## ðŸ“Š Performance and Scaling

### Performance Characteristics

- **Throughput**: 1000+ requests/second per instance
- **Latency**: <50ms average response time
- **Memory**: ~100MB baseline, ~200MB under load
- **CPU**: Optimized for horizontal scaling

### Scaling Strategies

#### Horizontal Scaling
```bash
# GKE Horizontal Pod Autoscaler
kubectl autoscale deployment auth-service --cpu-percent=70 --min=3 --max=20
```

#### Vertical Scaling
```yaml
resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

### Caching Strategy

```python
# Redis integration for token caching
import redis

redis_client = redis.Redis(host='redis-service', port=6379)

async def cache_token(user_id: int, token: str, expire: int):
    redis_client.setex(f"token:{user_id}", expire, token)
```

## ðŸ”’ Security Considerations

### Production Security Checklist

- [ ] Use strong JWT secret keys (256-bit minimum)
- [ ] Enable HTTPS/TLS termination
- [ ] Configure proper CORS policies
- [ ] Implement request rate limiting
- [ ] Use secrets management (Google Secret Manager)
- [ ] Enable audit logging
- [ ] Regular security updates
- [ ] Database connection encryption
- [ ] Container vulnerability scanning

### Secrets Management

```yaml
# Google Secret Manager integration
apiVersion: v1
kind: Secret
metadata:
  name: auth-secrets
type: Opaque
data:
  jwt-secret: <base64-encoded-secret>
  database-url: <base64-encoded-url>
```

## ðŸš¨ Troubleshooting

### Common Issues

#### Database Connection Errors
```bash
# Check database connectivity
curl http://localhost:8001/health

# Check logs
docker logs auth-service
```

#### JWT Token Issues
```bash
# Verify token manually
python -c "
import jwt
token = 'your-token-here'
secret = 'your-secret'
print(jwt.decode(token, secret, algorithms=['HS256']))
"
```

#### Rate Limiting
```bash
# Check rate limit status
curl -I http://localhost:8001/auth/login
# Look for X-RateLimit-* headers
```

### Monitoring and Alerts

#### Health Check Monitoring
```bash
# Kubernetes liveness probe
livenessProbe:
  httpGet:
    path: /health
    port: 8001
  initialDelaySeconds: 30
  periodSeconds: 10
```

#### Log Analysis
```bash
# Filter authentication events
kubectl logs -l app=auth-service | grep "auth\."

# Monitor error rates
kubectl logs -l app=auth-service | grep "ERROR"
```

## ðŸ“š Development

### Contributing

1. Fork the repository
2. Create a feature branch
3. Write tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

### Code Style

- Follow PEP 8 Python style guide
- Use type hints for all functions
- Document all public APIs
- Maintain test coverage >90%

### Project Structure

```
auth-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/          # FastAPI route handlers
â”‚   â”œâ”€â”€ models/       # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/      # Pydantic models
â”‚   â”œâ”€â”€ services/     # Business logic
â”‚   â””â”€â”€ utils/        # Shared utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ contract/     # API contract tests
â”‚   â””â”€â”€ integration/  # Integration tests
â”œâ”€â”€ Dockerfile        # Container definition
â”œâ”€â”€ pyproject.toml    # Dependencies and config
â””â”€â”€ main.py          # Application entry point
```

## ðŸ“– References

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [JWT Best Practices](https://tools.ietf.org/html/rfc7519)
- [SQLAlchemy 2.0 Guide](https://docs.sqlalchemy.org/en/20/)
- [Google Cloud Run](https://cloud.google.com/run/docs)
- [Kubernetes Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)

## ðŸ“„ License

This project is part of the Project Zero App platform. See the main repository for license information.

---

**ðŸ”— Related Services:**
- [Product Service](../product-service/README.md)
- [Order Service](../order-service/README.md)
- [Payment Service](../payment-service/README.md)